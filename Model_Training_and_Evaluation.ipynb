{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "from tensorflow import keras\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>subject</th>\n",
       "      <th>camera</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8602</th>\n",
       "      <td>data/Camera 2/train/c2/122510.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9558</th>\n",
       "      <td>data/Camera 2/train/c8/127615.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6827</th>\n",
       "      <td>data/Camera 1/train/c8/4100000000.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7614</th>\n",
       "      <td>data/Camera 1/train/c9/208700000000.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>data/Camera 1/train/c0/3519.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>data/Camera 1/train/c2/250.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4906</th>\n",
       "      <td>data/Camera 1/train/c4/978000.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>data/Camera 1/train/c2/445.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>data/Camera 1/train/c0/3045.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>data/Camera 1/train/c1/205.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848</th>\n",
       "      <td>data/Camera 1/train/c6/46900000.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8654</th>\n",
       "      <td>data/Camera 2/train/c2/41900.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>data/Camera 1/train/c0/2352.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075</th>\n",
       "      <td>data/Camera 1/train/c3/8570.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8886</th>\n",
       "      <td>data/Camera 2/train/c4/08622.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>data/Camera 1/train/c2/824.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504</th>\n",
       "      <td>data/Camera 1/train/c4/324000.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4098</th>\n",
       "      <td>data/Camera 1/train/c3/8810.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7930</th>\n",
       "      <td>data/Camera 1/train/c9/52800000000.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7828</th>\n",
       "      <td>data/Camera 1/train/c9/246000000000.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4710</th>\n",
       "      <td>data/Camera 1/train/c4/761000.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>data/Camera 1/train/c1/1663.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>data/Camera 1/train/c1/1629.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6623</th>\n",
       "      <td>data/Camera 1/train/c8/11270000000.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>data/Camera 1/train/c1/694.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>data/Camera 1/train/c6/122400000.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9417</th>\n",
       "      <td>data/Camera 2/train/c7/26458.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5780</th>\n",
       "      <td>data/Camera 1/train/c6/34200000.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>data/Camera 1/train/c4/893000.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4477</th>\n",
       "      <td>data/Camera 1/train/c4/285000.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>data/Camera 1/train/c2/146.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9613</th>\n",
       "      <td>data/Camera 2/train/c8/47218.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   image_path  label  subject  camera\n",
       "8602        data/Camera 2/train/c2/122510.jpg      2       44       2\n",
       "9558        data/Camera 2/train/c8/127615.jpg      8       44       2\n",
       "6827    data/Camera 1/train/c8/4100000000.jpg      8        7       1\n",
       "7614  data/Camera 1/train/c9/208700000000.jpg      9       20       1\n",
       "1446          data/Camera 1/train/c0/3519.jpg      0       25       1\n",
       "3131           data/Camera 1/train/c2/250.jpg      2        3       1\n",
       "4906        data/Camera 1/train/c4/978000.jpg      4       18       1\n",
       "3281           data/Camera 1/train/c2/445.jpg      2        7       1\n",
       "1149          data/Camera 1/train/c0/3045.jpg      0       21       1\n",
       "2471           data/Camera 1/train/c1/205.jpg      1       27       1\n",
       "5848      data/Camera 1/train/c6/46900000.jpg      6        6       1\n",
       "8654         data/Camera 2/train/c2/41900.jpg      2       36       2\n",
       "733           data/Camera 1/train/c0/2352.jpg      0       17       1\n",
       "4075          data/Camera 1/train/c3/8570.jpg      3       18       1\n",
       "8886         data/Camera 2/train/c4/08622.jpg      4       32       2\n",
       "3470           data/Camera 1/train/c2/824.jpg      2       17       1\n",
       "4504        data/Camera 1/train/c4/324000.jpg      4        5       1\n",
       "4098          data/Camera 1/train/c3/8810.jpg      3       18       1\n",
       "7930   data/Camera 1/train/c9/52800000000.jpg      9        5       1\n",
       "7828  data/Camera 1/train/c9/246000000000.jpg      9       25       1\n",
       "4710        data/Camera 1/train/c4/761000.jpg      4       14       1\n",
       "2348          data/Camera 1/train/c1/1663.jpg      1       21       1\n",
       "2316          data/Camera 1/train/c1/1629.jpg      1       21       1\n",
       "6623   data/Camera 1/train/c8/11270000000.jpg      8       25       1\n",
       "2833           data/Camera 1/train/c1/694.jpg      1        8       1\n",
       "5556     data/Camera 1/train/c6/122400000.jpg      6       28       1\n",
       "9417         data/Camera 2/train/c7/26458.jpg      7       34       2\n",
       "5780      data/Camera 1/train/c6/34200000.jpg      6        3       1\n",
       "4842        data/Camera 1/train/c4/893000.jpg      4       16       1\n",
       "4477        data/Camera 1/train/c4/285000.jpg      4        4       1\n",
       "3079           data/Camera 1/train/c2/146.jpg      2       27       1\n",
       "9613         data/Camera 2/train/c8/47218.jpg      8       36       2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\").sample(frac=1, random_state=42)\n",
    "val_df = pd.read_csv(\"data/val.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "train_df.head(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_path, label):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_jpeg(img, channels=0)\n",
    "    img = tf.image.resize(img, (224, 224))\n",
    "    img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
    "\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_train = train_df['image_path']\n",
    "image_path_test = test_df['image_path']\n",
    "image_path_val = val_df['image_path']\n",
    "label_train = train_df['label']\n",
    "label_test = test_df['label']\n",
    "label_val = val_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 15:14:50.195456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 15:14:50.210456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 15:14:50.210960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 15:14:50.211842: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-17 15:14:50.212475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 15:14:50.212893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 15:14:50.213278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 15:14:50.911616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 15:14:50.912047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 15:14:50.912428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 15:14:50.912779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3311 MB memory:  -> device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "#train dataset\n",
    "train_data = tf.data.Dataset.from_tensor_slices((image_path_train, label_train))\n",
    "train_data = train_data.map(preprocess, num_parallel_calls=6).shuffle(int(1e3)).batch(BATCH_SIZE).prefetch(1)\n",
    "#validation dataset\n",
    "val_data = tf.data.Dataset.from_tensor_slices((image_path_val, label_val))\n",
    "val_data = val_data.map(preprocess, num_parallel_calls=6).batch(BATCH_SIZE).prefetch(1)\n",
    "#test dataset\n",
    "test_data = tf.data.Dataset.from_tensor_slices((image_path_test, label_test))\n",
    "test_data = test_data.map(preprocess, num_parallel_calls=6).batch(BATCH_SIZE).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "logdir = \"logs/train_data/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(logdir)\n",
    "with file_writer.as_default():\n",
    "    # Don't forget to reshape.\n",
    "    for sample, _ in train_data.take(1):\n",
    "        pass\n",
    "    \n",
    "    tf.summary.image(\"Batch training data examples\", sample, max_outputs=32, step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                12810     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,270,794\n",
      "Trainable params: 2,236,682\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(NUM_CLASSES)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Nadam(learning_rate=1e-5)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True, monitor='val_accuracy')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 15:15:27.424416: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n",
      "2021-12-17 15:15:27.750451: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/308 [================>.............] - ETA: 50s - loss: 8.2604 - accuracy: 0.1166"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, epochs=100, validation_data=val_data, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "opt = keras.optimizers.Nadam(learning_rate=5e-6)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data, epochs=10, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(test_data, batch_size=64)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss \n",
    "num_epochs = 10\n",
    "epoch = 0\n",
    "\n",
    "while epoch < num_epochs:\n",
    "    model.train_on_batch(train_data)  \n",
    "    val_loss = model.evaluate(val_data)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        model.save(best_model_path) # OR model.save_weights()\n",
    "        print(\"Best model w/ val loss {} saved to {}\".format(val_loss, best_model_path))\n",
    "    \n",
    "    epoch += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
