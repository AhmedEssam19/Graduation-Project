{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pytorch-lightning gdown wandb --upgrade","metadata":{"execution":{"iopub.status.busy":"2022-04-09T02:05:46.200482Z","iopub.execute_input":"2022-04-09T02:05:46.200807Z","iopub.status.idle":"2022-04-09T02:06:15.869772Z","shell.execute_reply.started":"2022-04-09T02:05:46.200710Z","shell.execute_reply":"2022-04-09T02:06:15.868848Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Haarcascades files.\n!mkdir 'CheckPoints'\n!mkdir 'Haarcascades'\n!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\n!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_eye.xml\n!mv haarcascade_frontalface_default.xml 'Haarcascades/'\n!mv haarcascade_eye.xml 'Haarcascades/'","metadata":{"execution":{"iopub.status.busy":"2022-04-09T02:07:08.161842Z","iopub.execute_input":"2022-04-09T02:07:08.162113Z","iopub.status.idle":"2022-04-09T02:07:12.845546Z","shell.execute_reply.started":"2022-04-09T02:07:08.162085Z","shell.execute_reply":"2022-04-09T02:07:12.844455Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Dataset\n!gdown --id 1lQBEo3mIgZ4-gBY8XMwxzbSa_iHImdYp","metadata":{"execution":{"iopub.status.busy":"2022-04-09T02:08:17.397615Z","iopub.execute_input":"2022-04-09T02:08:17.397913Z","iopub.status.idle":"2022-04-09T02:08:39.676101Z","shell.execute_reply.started":"2022-04-09T02:08:17.397882Z","shell.execute_reply":"2022-04-09T02:08:39.675242Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!unzip dataset_B_Eye_Images.zip -d Dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-09T02:08:54.675313Z","iopub.execute_input":"2022-04-09T02:08:54.676028Z","iopub.status.idle":"2022-04-09T02:08:55.723766Z","shell.execute_reply.started":"2022-04-09T02:08:54.675981Z","shell.execute_reply":"2022-04-09T02:08:55.722952Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim  \nimport torchvision.transforms as transforms\nimport torchvision\nimport os\nfrom os.path import dirname, join\nimport pandas as pd\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets,models\nfrom torchvision.transforms import ToTensor\nimport torchmetrics\nfrom torch import nn\nfrom torchvision.io import read_image\nimport matplotlib.pyplot as plt\nfrom pytorch_lightning.loggers import WandbLogger\nimport pytorch_lightning as pl\nimport wandb\nimport random\nimport glob\nfrom PIL import Image\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2022-04-09T02:09:18.499631Z","iopub.execute_input":"2022-04-09T02:09:18.500253Z","iopub.status.idle":"2022-04-09T02:09:22.077801Z","shell.execute_reply.started":"2022-04-09T02:09:18.500213Z","shell.execute_reply":"2022-04-09T02:09:22.076934Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"wandb.login()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T02:11:11.552380Z","iopub.execute_input":"2022-04-09T02:11:11.553023Z","iopub.status.idle":"2022-04-09T02:11:15.574349Z","shell.execute_reply.started":"2022-04-09T02:11:11.552981Z","shell.execute_reply":"2022-04-09T02:11:15.573634Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"face_cascade = cv2.CascadeClassifier('Haarcascades/haar_models/haarcascade_frontalface_default.xml')\neye_cascade = cv2.CascadeClassifier('Haarcascades/haar_models/haarcascade_eye.xml')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T02:11:19.465520Z","iopub.execute_input":"2022-04-09T02:11:19.465804Z","iopub.status.idle":"2022-04-09T02:11:19.479177Z","shell.execute_reply.started":"2022-04-09T02:11:19.465745Z","shell.execute_reply":"2022-04-09T02:11:19.478415Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"OUTPUT_UNITS = 2\nshape = (24, 24)\nval_ratio = 0.25\nlr = 0.001\nBATCH_SIZE = 64\nepochs = 100\nData_Path = 'Dataset/dataset_B_Eye_Images'\nSave_Dir = 'CheckPoints/'\nconfig = {\n    'learning_rate': lr,\n    'batch_size': BATCH_SIZE,\n    'epochs': epochs,\n    'input_shape': shape\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-09T02:11:25.884163Z","iopub.execute_input":"2022-04-09T02:11:25.884423Z","iopub.status.idle":"2022-04-09T02:11:25.889875Z","shell.execute_reply.started":"2022-04-09T02:11:25.884394Z","shell.execute_reply":"2022-04-09T02:11:25.888684Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def resize(image, bbox):\n    (x,y,w,h) = bbox\n    eye = image[y:y + h, x:x + w]\n    return Image.fromarray(cv2.resize(eye, shape))","metadata":{"execution":{"iopub.status.busy":"2022-04-09T02:11:29.503247Z","iopub.execute_input":"2022-04-09T02:11:29.503973Z","iopub.status.idle":"2022-04-09T02:11:29.508259Z","shell.execute_reply.started":"2022-04-09T02:11:29.503934Z","shell.execute_reply":"2022-04-09T02:11:29.507364Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class CreateDataset(Dataset):\n    def __init__(self, images, labels, transform=False):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, index):   \n        image = self.images[index]\n        label = self.labels[index]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2022-04-09T02:11:32.069125Z","iopub.execute_input":"2022-04-09T02:11:32.069661Z","iopub.status.idle":"2022-04-09T02:11:32.075474Z","shell.execute_reply.started":"2022-04-09T02:11:32.069622Z","shell.execute_reply":"2022-04-09T02:11:32.074846Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class DataSetFactory:\n    def __init__(self):\n        images = []\n        labels = []\n\n        files = list(map(lambda x: {'img_path': x, 'label':1}, glob.glob(Data_Path+'/openRightEyes/*.jpg')))\n        files.extend(list(map(lambda x: {'img_path': x, 'label':1}, glob.glob(Data_Path+'/openLeftEyes/*.jpg'))))\n        files.extend(list(map(lambda x: {'img_path': x, 'label':0}, glob.glob(Data_Path+'/closedLeftEyes/*.jpg'))))\n        files.extend(list(map(lambda x: {'img_path': x, 'label':0}, glob.glob(Data_Path+'/closedRightEyes/*.jpg'))))\n        random.shuffle(files)\n        for file in files:\n            img = cv2.imread(file['img_path'])\n            images.append(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n            labels.append(file['label'])\n\n        val_length = int(len(images) * val_ratio)\n        val_images = images[:val_length]\n        val_labels = labels[:val_length]\n        train_images = images[val_length:]\n        train_labels = labels[val_length:]\n\n        print('training size %d : val size %d' % (len(train_images), len(val_images)))\n\n        train_transform = transforms.Compose([\n            ToTensor(),\n        ])\n        val_transform = transforms.Compose([\n            ToTensor(),\n        ])\n        #print({'images': val_images, 'labels': val_labels})\n        self.training = CreateDataset(images=images, labels=labels, transform=train_transform)\n        self.validation = CreateDataset(images=val_images, labels=val_labels, transform=val_transform)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T02:12:01.404483Z","iopub.execute_input":"2022-04-09T02:12:01.404740Z","iopub.status.idle":"2022-04-09T02:12:01.415843Z","shell.execute_reply.started":"2022-04-09T02:12:01.404712Z","shell.execute_reply":"2022-04-09T02:12:01.414766Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"dataset = DataSetFactory()\ntrain_dataloader = DataLoader(dataset.training, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nval_dataloader = DataLoader(dataset.validation, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T02:12:04.862916Z","iopub.execute_input":"2022-04-09T02:12:04.863845Z","iopub.status.idle":"2022-04-09T02:12:05.047981Z","shell.execute_reply.started":"2022-04-09T02:12:04.863760Z","shell.execute_reply":"2022-04-09T02:12:05.046510Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class SeparableConv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False):\n        super(SeparableConv2d, self).__init__()\n        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, dilation, groups=in_channels,\n                                   bias=bias)\n        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, 1, 0, 1, 1, bias=bias)\n\n    def forward(self, x):\n        x = self.depthwise(x)\n        x = self.pointwise(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-04-09T02:12:08.921741Z","iopub.execute_input":"2022-04-09T02:12:08.922289Z","iopub.status.idle":"2022-04-09T02:12:08.929003Z","shell.execute_reply.started":"2022-04-09T02:12:08.922249Z","shell.execute_reply":"2022-04-09T02:12:08.928314Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(ResidualBlock, self).__init__()\n\n        self.residual_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=2,\n                                       bias=False)\n        self.residual_bn = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n\n        self.sepConv1 = SeparableConv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, bias=False,\n                                        padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n        self.relu = nn.ReLU()\n\n        self.sepConv2 = SeparableConv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, bias=False,\n                                        padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n        self.maxp = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n    def forward(self, x):\n        res = self.residual_conv(x)\n        res = self.residual_bn(res)\n        x = self.sepConv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.sepConv2(x)\n        x = self.bn2(x)\n        x = self.maxp(x)\n        return res + x","metadata":{"execution":{"iopub.status.busy":"2022-04-09T02:12:12.722610Z","iopub.execute_input":"2022-04-09T02:12:12.723313Z","iopub.status.idle":"2022-04-09T02:12:12.733288Z","shell.execute_reply.started":"2022-04-09T02:12:12.723275Z","shell.execute_reply":"2022-04-09T02:12:12.732356Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class Model(pl.LightningModule):\n    def __init__(self, output_units, learning_rate):\n        super(Model, self).__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(8, affine=True, momentum=0.99, eps=1e-3)\n        self.relu1 = nn.ReLU()\n        self.conv2 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, stride=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(8, momentum=0.99, eps=1e-3)\n        self.relu2 = nn.ReLU()\n\n        self.module1 = ResidualBlock(in_channels=8, out_channels=16)\n        self.module2 = ResidualBlock(in_channels=16, out_channels=32)\n        self.module3 = ResidualBlock(in_channels=32, out_channels=64)\n        self.module4 = ResidualBlock(in_channels=64, out_channels=128)\n\n        self.last_conv = nn.Conv2d(in_channels=128, out_channels=output_units, kernel_size=3, padding=1)\n        self.avgp = nn.AdaptiveAvgPool2d((1, 1))\n        \n        self.criterion = nn.CrossEntropyLoss()\n        self.train_acc = torchmetrics.Accuracy()\n        self.val_acc = torchmetrics.Accuracy()\n        \n        self.learning_rate = learning_rate\n        self.save_hyperparameters()\n        \n    def forward(self, input_data):\n        x = input_data\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu1(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu2(x)\n        x = self.module1(x)\n        x = self.module2(x)\n        x = self.module3(x)\n        x = self.module4(x)\n        x = self.last_conv(x)\n        x = self.avgp(x)\n        x = x.view((x.shape[0], -1))\n        return x\n        \n    def training_step(self, batch, batch_idx):\n        input_data, targets = batch\n        preds = self(input_data)\n        loss = self.criterion(preds, targets)\n        self.log('train_loss', loss)\n        self.train_acc(preds, targets)\n        self.log('train_acc', self.train_acc, on_step=True, on_epoch=False, prog_bar=True)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        self._evaluate(batch, 'val')\n        \n    def test_step(self, batch, batch_nb):\n        self._evaluate(batch, 'test')\n        \n    def _evaluate(self, batch, name):\n        input_data, targets = batch\n        preds = self(input_data)\n        loss = self.criterion(preds, targets)\n        self.log(f'{name}_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.val_acc(preds, targets)\n        self.log(f'{name}_acc', self.val_acc, on_step=False, on_epoch=True, prog_bar=True)\n        \n    def predict_step(self, batch, batch_idx):\n        input_data, targets = batch\n        preds = self(input_data)\n        return torch.argmax(preds, dim=1)\n        \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=self.learning_rate, max_lr=1e-4, cycle_momentum=False)\n        return [optimizer],[scheduler]","metadata":{"execution":{"iopub.status.busy":"2022-04-09T02:12:15.683040Z","iopub.execute_input":"2022-04-09T02:12:15.683616Z","iopub.status.idle":"2022-04-09T02:12:15.705157Z","shell.execute_reply.started":"2022-04-09T02:12:15.683581Z","shell.execute_reply":"2022-04-09T02:12:15.704436Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model = Model(OUTPUT_UNITS, lr)\n\ncallbacks = [\n          pl.callbacks.ModelCheckpoint(monitor='val_acc', dirpath=Save_Dir, verbose=True, mode='max', filename='Drowsiness-{val_acc:.4f}'),\n          pl.callbacks.EarlyStopping(monitor='val_acc', patience=20, verbose=True, mode='max')\n]\n\nwandb_logger = WandbLogger(project=\"Driver-Drowsiness\", config=config)\ntrainer = pl.Trainer(max_epochs=epochs, callbacks=callbacks, gpus=1, logger=wandb_logger)    \ntrainer.fit(model, train_dataloader, val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T02:12:20.070405Z","iopub.execute_input":"2022-04-09T02:12:20.070665Z","iopub.status.idle":"2022-04-09T02:14:03.814362Z","shell.execute_reply.started":"2022-04-09T02:12:20.070635Z","shell.execute_reply":"2022-04-09T02:14:03.813537Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"trainer.validate(dataloaders=val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T02:14:09.632041Z","iopub.execute_input":"2022-04-09T02:14:09.632600Z","iopub.status.idle":"2022-04-09T02:14:10.067460Z","shell.execute_reply.started":"2022-04-09T02:14:09.632560Z","shell.execute_reply":"2022-04-09T02:14:10.066714Z"},"trusted":true},"execution_count":20,"outputs":[]}]}